#!/usr/bin/python3
#
# Live Media Creator Web Composer Demo
#
# Copyright (C) 2016  Red Hat, Inc.
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# Author(s): Brian C. Lane <bcl@redhat.com>
#
import logging
log = logging.getLogger("lmc-web-composer")

import os
import sys
import tempfile
import subprocess
import shutil
import glob
import threading
from collections import namedtuple
import dnf
from binascii import hexlify
import queue

# Use pykickstart to calculate disk image size
from pykickstart.parser import KickstartParser
from pykickstart.version import makeVersion

# Use Mako templates for appliance builder descriptions
from mako.template import Template
from mako.exceptions import text_error_template

# Use the Lorax treebuilder branch for iso creation
from pylorax import ArchData, setup_logging, find_templates
from pylorax.base import DataHolder
from pylorax.treebuilder import TreeBuilder
from pylorax.treebuilder import findkernels
from pylorax.sysutils import joinpaths, remove
from pylorax.imgutils import PartitionMount, mkext4img
from pylorax.imgutils import mount, umount, Mount
from pylorax.imgutils import mksquashfs
from pylorax.imgutils import copytree
from pylorax.executils import execWithRedirect, execReadlines
from pylorax.monitor import LogMonitor
from pylorax.cmdline import lmc_composer_parser
import pylorax.modules

from pyanaconda.queuefactory import QueueFactory

# Default parameters for rebuilding initramfs, override with --dracut-args
DRACUT_DEFAULT = ["--xz", "--add", "livenet dmsquash-live convertfs pollcdrom qemu qemu-net",
                  "--omit", "plymouth", "--no-hostonly", "--debug", "--no-early-microcode"]

ROOT_PATH = "/mnt/sysimage/"
RUNTIME = "images/install.img"

DEFAULT_REPOS = ["http://dl.fedoraproject.org/pub/fedora/linux/releases/24/Everything/x86_64/os/",
                 "http://dl.fedoraproject.org/pub/fedora/linux/updates/24/x86_64/"]
#MODULE_REPOS = "http://dev.fed-mod.org/modularity/fedora-24-mod/"
MODULE_REPOS = "http://newcutlet.install.bos.redhat.com/pub/fedora-modularity/fedora-24-mod/"

class InstallError(Exception):
    pass


class FakeDNF(object):
    """
    A minimal DNF object suitable for passing to RuntimeBuilder

    lmc uses RuntimeBuilder to run the arch specific iso creation
    templates, so the the installroot config value is the important part of
    this. Everything else should be a nop.
    """
    def __init__(self, conf):
        self.conf = conf

    def reset(self):
        pass


def get_arch(mount_dir):
    """
    Get the kernel arch

    :returns: Arch of first kernel found at mount_dir/boot/ or i386
    :rtype: str
    """
    kernels = findkernels(mount_dir)
    if not kernels:
        return "i386"
    return kernels[0].arch

def squashfs_args():
    """ Returns the compression type and args to use when making squashfs

    :returns: tuple of compression type and args
    :rtype: tuple
    """
    compression = "xz"
    arch = ArchData(os.uname().machine)
    if compression == "xz" and arch.bcj:
        compressargs = ["-Xbcj", arch.bcj]
    else:
        compressargs = []
    return (compression, compressargs)


def make_livecd(config, mount_dir, work_dir):
    """
    Take the content from the disk image and make a livecd out of it

    :param config: options passed to livemedia-creator
    :type config: configuration options
    :param str mount_dir: Directory tree to compress
    :param str work_dir: Output compressed image to work_dir+images/install.img

    This uses wwood's squashfs live initramfs method:
     * put the real / into LiveOS/rootfs.img
     * make a squashfs of the LiveOS/rootfs.img tree
     * This is loaded by dracut when the cmdline is passed to the kernel:
       root=live:CDLABEL=<volid> rd.live.image
    """
    kernel_arch = get_arch(mount_dir)

    arch = ArchData(kernel_arch)
    # TODO: Need to get release info from someplace...
    product = DataHolder(name=config.project, version=config.releasever, release="",
                            variant="", bugurl="", isfinal=False)

    # Link /images to work_dir/images to make the templates happy
    if os.path.islink(joinpaths(mount_dir, "images")):
        os.unlink(joinpaths(mount_dir, "images"))
    execWithRedirect("/bin/ln", ["-s", joinpaths(work_dir, "images"),
                                 joinpaths(mount_dir, "images")])

    # The templates expect the config files to be in /tmp/config_files
    # I think these should be release specific, not from lorax, but for now
    configdir = joinpaths(config.lorax_templates,"live/config_files/")
    configdir_path = "tmp/config_files"
    fullpath = joinpaths(mount_dir, configdir_path)
    if os.path.exists(fullpath):
        remove(fullpath)
    copytree(configdir, fullpath)

    isolabel = "{0.name}-{0.version}-{1.basearch}".format(product, arch)
    if len(isolabel) > 32:
        isolabel = isolabel[:32]
        log.warning("Truncating isolabel to 32 chars: %s", isolabel)

    tb = TreeBuilder(product=product, arch=arch, domacboot=config.domacboot,
                     inroot=mount_dir, outroot=work_dir,
                     runtime=RUNTIME, isolabel=isolabel,
                     templatedir=joinpaths(config.lorax_templates,"live/"))
    log.info("Rebuilding initrds")
    tb.rebuild_initrds(add_args=config.dracut_args)
    log.info("Building boot.iso")
    tb.build()

    return work_dir


def novirt_log_check(log_check, proc, cancel_q):
    """
    Check to see if there has been an error in the logs

    :param log_check: method to call to check for an error in the logs
    :param proc: Popen object for the anaconda process
    :param cancel_q: QueueFactory object to check for a cancel command
    :returns: True if the process has been terminated

    The log_check method should return a True if an error has been detected.
    When an error is detected the process is terminated and this returns True
    """
    if log_check():
        proc.terminate()
        return True

    if not cancel_q:
        return False

    try:
        (code, args) = cancel_q.q.get(False)
        if code == cancel_q.CANCEL_CODE_CANCEL:
            proc.terminate()
            return True
    except queue.Empty:
        pass

    return False


def anaconda_cleanup(dirinstall_path):
    """
    Cleanup any leftover mounts from anaconda

    :param str dirinstall_path: Path where anaconda mounts things
    :returns: True if cleanups were successful. False if any of them failed.

    If anaconda crashes it may leave things mounted under this path. It will
    typically be set to /mnt/sysimage/

    Attempts to cleanup may also fail. Catch these and continue trying the
    other mountpoints.
    """
    rc = True
    dirinstall_path = os.path.abspath(dirinstall_path)
    # unmount filesystems
    with open("/proc/mounts") as mounts:
        for mounted in reversed(mounts.readlines()):
            (_device, mountpoint, _rest) = mounted.split(" ", 2)
            if mountpoint.startswith(dirinstall_path) and os.path.ismount(mountpoint):
                try:
                    umount(mountpoint)
                except subprocess.CalledProcessError:
                    log.error("Cleanup of %s failed. See program.log for details", mountpoint)
                    rc = False
    return rc


def novirt_install(config, ks_file, disk_img, disk_size, cancel_q):
    """
    Use Anaconda to install to a disk image

    :param config: options passed to livemedia-creator
    :type config: config options
    :param str disk_img: The full path to the disk image to be created
    :param int disk_size: The size of the disk_img in MiB

    """
    dirinstall_path = ROOT_PATH

    # Clean up /tmp/ from previous runs to prevent stale info from being used
    for path in ["/tmp/yum.repos.d/", "/tmp/yum.cache/"]:
        if os.path.isdir(path):
            shutil.rmtree(path)

    args = ["--kickstart", ks_file, "--cmdline"]
    if config.proxy:
        args += ["--proxy", config.proxy]

    # Make a blank fs image
    args += ["--dirinstall"]

    mkext4img(None, disk_img, label="Anaconda", size=disk_size * 1024**2)
    if not os.path.isdir(dirinstall_path):
        os.mkdir(dirinstall_path)
    mount(disk_img, opts="loop", mnt=dirinstall_path)

    log_monitor = LogMonitor(log_path=config.anaconda_log, timeout=None)
    args += ["--remotelog", "%s:%s" % (log_monitor.host, log_monitor.port)]

    # Make sure anaconda has the right product and release
    log.info("Running anaconda.")
    try:
        for line in execReadlines("anaconda", args, reset_lang=False,
                                  env_add={"ANACONDA_PRODUCTNAME": config.project,
                                           "ANACONDA_PRODUCTVERSION": config.releasever},
                                  callback=lambda p: not novirt_log_check(log_monitor.server.log_check, p, cancel_q)):
            log.info(line)

        # Make sure the new filesystem is correctly labeled
        setfiles_args = ["-e", "/proc", "-e", "/sys", "-e", "/dev",
                         "/etc/selinux/targeted/contexts/files/file_contexts", "/"]

        # setfiles may not be available, warn instead of fail
        try:
            if "--dirinstall" in args:
                execWithRedirect("setfiles", setfiles_args, root=dirinstall_path)
            else:
                with PartitionMount(disk_img) as img_mount:
                    if img_mount and img_mount.mount_dir:
                        execWithRedirect("setfiles", setfiles_args, root=img_mount.mount_dir)
        except (subprocess.CalledProcessError, OSError) as e:
            log.warning("Running setfiles on install tree failed: %s", str(e))

    except (subprocess.CalledProcessError, OSError) as e:
        log.error("Running anaconda failed: %s", e)
        raise InstallError("novirt_install failed")
    finally:
        log_monitor.shutdown()

        # Move the anaconda logs over to a log directory
        log_dir = os.path.abspath(os.path.dirname(config.logfile))
        log_anaconda = joinpaths(log_dir, "lmc-web-composer")
        if not os.path.isdir(log_anaconda):
            os.mkdir(log_anaconda)
        for l in glob.glob("/tmp/*log")+glob.glob("/tmp/anaconda-tb-*"):
            shutil.copy2(l, log_anaconda)
            os.unlink(l)
        if os.path.exists(config.anaconda_log):
            os.unlink(config.anaconda_log)

        # Make sure any leftover anaconda mounts have been cleaned up
        if not anaconda_cleanup(dirinstall_path):
            raise InstallError("novirt_install cleanup of anaconda mounts failed.")


def make_squashfs(disk_img, work_dir):
    """
    Create a squashfs image of an unpartitioned filesystem disk image

    :param str disk_img: Path to the unpartitioned filesystem disk image
    :param str work_dir: Output compressed image to work_dir+images/install.img
    :param str compression: Compression type to use
    :returns: True if squashfs creation was successful. False if there was an error.
    :rtype: bool

    Take disk_img and put it into LiveOS/rootfs.img and squashfs this
    tree into work_dir+images/install.img

    fsck.ext4 is run on the disk image to make sure there are no errors and to zero
    out any deleted blocks to make it compress better. If this fails for any reason
    it will return False and log the error.
    """
    # Make sure free blocks are actually zeroed so it will compress
    rc = execWithRedirect("/usr/sbin/fsck.ext4", ["-y", "-f", "-E", "discard", disk_img])
    if rc != 0:
        log.error("Problem zeroing free blocks of %s", disk_img)
        return False

    liveos_dir = joinpaths(work_dir, "runtime/LiveOS")
    os.makedirs(liveos_dir)
    os.makedirs(os.path.dirname(joinpaths(work_dir, RUNTIME)))

    rc = execWithRedirect("/bin/ln", [disk_img, joinpaths(liveos_dir, "rootfs.img")])
    if rc != 0:
        shutil.copy2(disk_img, joinpaths(liveos_dir, "rootfs.img"))

    compression, compressargs = squashfs_args()
    mksquashfs(joinpaths(work_dir, "runtime"),
               joinpaths(work_dir, RUNTIME), compression, compressargs)
    remove(joinpaths(work_dir, "runtime"))
    return True

def calculate_disk_size(ks):
    """ Calculate the disk size from the kickstart

    :param str ks: Path to the kickstart to use for the installation
    :returns: Disk size in MiB
    :rtype: int
    """
    # Disk size for a filesystem image should only be the size of /
    # to prevent surprises when using the same kickstart for different installations.
    unique_partitions = dict((p.mountpoint, p) for p in ks.handler.partition.partitions)
    disk_size = 2 + sum(p.size for p in unique_partitions.values() if p.mountpoint == "/")
    log.info("Using disk size of %sMiB", disk_size)
    return disk_size


def make_image(config, ks_file, cancel_q):
    """
    Install to a disk image

    :param str ks_file: Path to the kickstart to use for the installation
    :returns: Path of the image created
    :rtype: str

    Use qemu+boot.iso or anaconda to install to a disk image.
    """
    # Parse the kickstart
    ks_version = makeVersion()
    ks = KickstartParser(ks_version, errorsAreFatal=False, missingIncludeIsFatal=False)
    ks.readKickstart(ks_file)

    errors = []
    # live iso usually needs dracut-live so warn the user if it is missing
    if "dracut-live" not in ks.handler.packages.packageList:
        errors.append("dracut-live package is missing from the kickstart.")

    if ks.handler.method.method not in ("url", "nfs") \
       and not ks.handler.ostreesetup.seen:
        errors.append("Only url, nfs and ostreesetup install methods are currently supported."
                      "Please fix your kickstart file." )

    if ks.handler.method.method in ("url", "nfs") and not ks.handler.network.seen:
        errors.append("The kickstart must activate networking if "
                      "the url or nfs install method is used.")

    if ks.handler.displaymode.displayMode is not None:
        errors.append("The kickstart must not set a display mode (text, cmdline, "
                      "graphical), this will interfere with livemedia-creator.")

    # Make sure the kickstart isn't using autopart and only has a / mountpoint
    part_ok = not any(p for p in ks.handler.partition.partitions
                      if p.mountpoint not in ["/", "swap"])
    if not part_ok or ks.handler.autopart.seen:
        errors.append("Filesystem images must use a single / part, not autopart or "
                      "multiple partitions. swap is allowed but not used.")

    if errors:
        list(log.error(e) for e in errors)
        raise InstallError("Problem with the kickstart")

    disk_img = tempfile.mktemp(prefix="lmc-disk-", suffix=".img")
    log.info("disk_img = %s", disk_img)
    disk_size = calculate_disk_size(ks)
    try:
        novirt_install(config, ks_file, disk_img, disk_size, cancel_q)
    except InstallError as e:
        log.error("Install failed: %s", e)
        log.info("Removing bad disk image")
        os.unlink(disk_img)
        raise

    log.info("Disk Image install successful")
    return disk_img


def default_image_name(compression, basename):
    """ Return a default image name with the correct suffix for the compression type.

    :param str compression: Compression type
    :param str basename: Base filename
    :returns: basename with compression suffix

    If the compression is unknown it defaults to xz
    """
    SUFFIXES = {"xz": ".xz", "gzip": ".gz", "bzip2": ".bz2", "lzma": ".lzma"}
    return basename + SUFFIXES.get(compression, ".xz")



def make_novirt_liveiso(config, ks_file, iso_dest, cancel_q):
    """ Run anaconda to build a live iso

    :param ks_file: Path to kickstart file
    :param iso_dest: Path to output iso file
    """
    # Make the image. Output of this is either a partitioned disk image or a fsimage
    try:
        disk_img = make_image(config, ks_file, cancel_q)
    except InstallError as e:
        log.error("ERROR: Image creation failed: %s", e)
        return False

    # Make the iso from the disk_img
    result_dir = None
    work_dir = tempfile.mkdtemp(prefix="lmc-work-")
    log.info("working dir is %s", work_dir)

    if not make_squashfs(disk_img, work_dir):
        log.error("squashfs.img creation failed")
        return False

    with Mount(disk_img, opts="loop") as mount_dir:
        result_dir = make_livecd(config, mount_dir, work_dir)

    if not result_dir:
        log.error("Live iso creation failed")
        return False

    boot_iso = joinpaths(result_dir, "images/boot.iso")
    if not os.path.exists(boot_iso):
        log.error("Live iso creation failed: %s is missing.", boot_iso)
        return False

    if not os.path.exists(os.path.dirname(iso_dest)):
        os.makedirs(os.path.dirname(iso_dest))
    shutil.move(boot_iso, iso_dest)
    shutil.rmtree(result_dir)

    if disk_img:
        os.unlink(disk_img)
        log.info("Disk image erased")
        disk_img = None


def get_dbo(tempdir, repositories, releasever, best):
    """ Create a dnf Base object and setup the repositories and installroot

        :param list repositories: List of repositories to use for the installation
        :param string releasever: Release version to pass to dnf

    """
    def sanitize_repo(repo):
        """Convert bare paths to file:/// URIs, and silently reject protocols unhandled by yum"""
        if repo.startswith("/"):
            return "file://{0}".format(repo)
        elif any(repo.startswith(p) for p in ('http://', 'https://', 'ftp://', 'file://')):
            return repo
        else:
            return None

    # sanitize the repositories
    repositories = list(sanitize_repo(r) for r in repositories)

    # remove invalid repositories
    repositories = list(r for r in repositories if r)

    cachedir = os.path.join(tempdir, "dnf.cache")
    if not os.path.isdir(cachedir):
        os.mkdir(cachedir)

    logdir = os.path.join(tempdir, "dnf.logs")
    if not os.path.isdir(logdir):
        os.mkdir(logdir)

    installroot = os.path.join(tempdir, "installroot")
    if not os.path.isdir(installroot):
        os.mkdir(installroot)

    dnfbase = dnf.Base()
    conf = dnfbase.conf

    log.info("Use highest NVR package? %s", best)
    conf.best = best

    # setup dirs.
    conf.logdir = logdir
    conf.cachedir = cachedir

    # Turn off logging to the console
    conf.debuglevel = 10
    conf.errorlevel = 0
    conf.debug_solver = True

    conf.releasever = releasever
    conf.installroot = installroot
    conf.prepend_installroot('persistdir')
#    conf.tsflags.append('nodocs')

    # add the repositories
    for i, r in enumerate(repositories):
        if "SRPM" in r or "srpm" in r:
            log.info("Skipping source repo: %s", r)
            continue
        repo_name = "lorax-repo-%d" % i
        repo = dnf.repo.Repo(repo_name, cachedir)
        repo.baseurl = [r]
        repo.skip_if_unavailable = False
        repo.enable()
        dnfbase.repos.add(repo)
        log.info("Added '%s': %s", repo_name, r)
        log.info("Fetching metadata for %s", repo_name)
        try:
            repo.load()
        except dnf.exceptions.RepoError as e:
            log.error("Error fetching metadata for %s: %s", repo_name, e)
            return None
        log.info("Fetching metadata for %s finished.", repo_name)

    dnfbase.fill_sack(load_system_repo=False)
    dnfbase.read_comps()

    return dnfbase


def get_dnf_transaction(dbo, packages):
    dbo.reset(goal=True, sack=False, repos=False)

    for pkg in packages:
        log.info("Adding %s to the transaction", pkg)
        try:
            dbo.install(pkg)
        except Exception as e:          # pylint: disable=broad-except
            log.error("Failed to install %s\n%s", pkg, e)

    try:
        log.info("Checking dependencies")
        dbo.resolve()
    except dnf.exceptions.DepsolveError as e:
        log.error("Dependency check failed: %s", e)
        raise

    log.info("%d packages selected", len(dbo.transaction))
    if len(dbo.transaction) == 0:
        raise Exception("No packages in transaction")

    return [pkg.pkgtup for pkg in dbo.transaction.install_set]


def get_pkg_info(pkg):
    """ Get detailed info on the package.

    Returns a dict of the attributes.
    """
    PKG_ATTRS = ("arch", "buildtime", "description", "downloadsize", "evr", "installsize",
                "installtime", "license", "name", "packager", "size", "sourcerpm", "summary",
                "url", "files")

    info = {}
    for attr in PKG_ATTRS:
        info[attr] = getattr(pkg, attr, "")

    info["chksum"] = hexlify(pkg.chksum[1]).decode()

    PKG_LISTS = ("conflicts", "enhances", "obsoletes", "provides", "recommends", "requires",
                "suggests", "supplements")
    for l in PKG_LISTS:
        info[l] = [str(p) for p in getattr(pkg, l, [])]

    return info


def run_dnf_thread(config, dnf_q):
    """ Handle all DNF object operations in this thread.

    :param queue: A queue used to receive commands

    Requests that require a reply will pass in an instance of a reply queue
    that takes a q.send_reply(<dict>) response. A new reply queue must be
    created for each request.
    """
    dbo = get_dbo(config.dnf_dir, DEFAULT_REPOS, 24, True)

    # maintain a DNF base object
    # Answer queries from other threads
    # reset/update the repos
    while True:
        (code, args) = dnf_q.q.get(True)

        if code == dnf_q.DNF_CODE_QUIT:
            break
        elif code == dnf_q.DNF_CODE_REPOS:
            if len(args) == 0 or len(args[0]) == 0:
                continue
            dbo = get_dbo(config.dnf_dir, args[0], 24, True)

        elif code == dnf_q.DNF_CODE_TRANSACTION:
            if len(args) < 2 or len(args[0]) == 0:
                continue
            q = args[1]

            try:
                packages = get_dnf_transaction(dbo, args[0])
            except Exception as e:          # pylint: disable=broad-except
                q.send_reply({"error": str(e)})
                continue

            q.send_reply({"packages": packages})

        elif code == dnf_q.DNF_CODE_INFO:
            if len(args) < 2 or len(args[0]) == 0:
                continue
            q = args[1]

            # Get the details about all the packages
            reply = {}
            query = dbo.sack.query()
            available = query.available()
            for pkg in args[0]:
                answer = available.filter(name=pkg)
                for pkg in answer:
                    info = get_pkg_info(pkg)
                    reply[pkg.name] = info

            q.send_reply(reply)


def start_dnf_thread(config, dnf_q):
    t = threading.Thread(target=run_dnf_thread, args=(config, dnf_q,))
    t.daemon = True
    t.start()

    return True


def start_compose_thread(config, iso_dest, url, repos=None, packages=None, cancel_q=None):
    """ Start a thread running the compose

    :param url: Primary repo URL
    :param repos: List of extra repositories
    :param packages: List of extra packages
    :returns: The thread object for the comopose thread
    """

    # Construct a kickstart file from a template
    if config.proxy:
        proxy_str = "--proxy=%s" % config.proxy
    else:
        proxy_str = ""

    ks_vars = {"url": url, "repos" : repos or [], "packages": packages or [],
               "proxy": proxy_str}
    try:
        result = Template(filename=config.ks_template).render(**ks_vars)
    except Exception:
        log.error(text_error_template().render())
        raise

    # XXX - Need to clean this file up later
    tmp_ks = tempfile.mktemp(prefix="lmc-compose-", suffix=".ks")
    with open(tmp_ks, "w") as f:
        f.write(result)
    log.info("Wrote kickstart to %s", tmp_ks)

    # XXX - How are we going to monitor this? Stop it? Tell when it is done?
    t = threading.Thread(target=make_novirt_liveiso, args=(config, tmp_ks, iso_dest, cancel_q))
    t.daemon = True
    t.start()

    return t


def new_reply_q():
    """ Return a new reply queue"""
    reply_q = QueueFactory("dnf")
    reply_q.addMessage("reply", 1)      # dict
    return reply_q


def run_bottle_app(config):
    """ Run the web application"""
    TEMPLATE_FILES = config.share_dir+"/html/templates/"
    STATIC_FILES = config.share_dir+"/html/static/"
    list(os.makedirs(p) for p in (TEMPLATE_FILES, STATIC_FILES) if not os.path.exists(p))

    # Supported compose types
    COMPOSE_TYPES = {"iso": True, "disk-image": False, "fs-image": False, "ami": False,
                     "tar": False, "live-pxe": False, "live-ostree": False, "oci": False,
                     "vagrant": False, "qcow2": False, "vmdk": False, "vhdx": False}

    import bottle
    from bottle import abort, post, route, run, static_file, request
    from bottle import mako_template as template
    bottle.TEMPLATE_PATH = [TEMPLATE_FILES]

    dnf_q = QueueFactory("dnf")
    dnf_q.addMessage("repos", 1)        # List of repos to use
    dnf_q.addMessage("transaction", 2)  # list, queue
    dnf_q.addMessage("info", 2)         # string, queue
    dnf_q.addMessage("quit", 0)

    rc = start_dnf_thread(config, dnf_q)
    if not rc:
        log.error("Failed to start DNF thread.")
        return False

    # XXX Total hack to keep track of running compose's thread object
    compose_lock = threading.Lock()
    global compose_thread
    compose_thread = None

    # A queue to cancel running the Anaconda process
    cancel_q = QueueFactory("cancel")
    cancel_q.addMessage("cancel", 0)

    # pylint: disable=unused-variable
    # Setup the routes
    @route('/static/<filepath:path>')
    def server_static(filepath):
        # A mimetype of "True" is the default and tells bottle to guess from the
        # file extension. .iso is not one of those extensions, so help it out a
        # bit instead of crashing the browswer with millions of bytes of "text".
        mimetype = True
        if filepath.endswith('.iso'):
            mimetype = "application/octet-stream"
        return static_file(filepath, mimetype=mimetype, root=STATIC_FILES)

    @route('/hello')
    @route('/hello/<name>')
    def hello(name="World"):
        return template("hello", name=name)

    @route('/isos')
    def isos():
        files = [os.path.basename(f) for f in glob.glob(STATIC_FILES+"*.iso")]
        return template("isos", files=files)

    @route('/')
    def index():
        # XXX make URL configurable here, too
        # XXX using the module "summary" properties could make sense but right
        # now the summaries are usless
        module_list = pylorax.modules.parse_json(MODULE_REPOS)
        return template("index", modules=[m['name'] for m in module_list])

    @route('/api/v0/isos')
    def json_isos():
        """ Return a JSON string of the isos in the static directory."""
        return {"isos": [os.path.basename(f) for f in glob.glob(STATIC_FILES+"*.iso")]}

    @post('/api/v0/compose')
    def compose():
        # XXX - Eventually this will come from the user
        url = DEFAULT_REPOS[0]
        module_url = MODULE_REPOS

        module_list = request.forms.getall('module')
        if not module_list:
            abort(500, "No module specified.")

        # NOTE: compose_type is not actually used for the compose
        compose_type = request.forms.get('type')
        if not compose_type or not COMPOSE_TYPES.get(compose_type, False):
            abort(500, "%s is not a supported compose type." % compose_type)

        repos = set()
        packages = set()
        for module in module_list:
            mod_repos, mod_packages = pylorax.modules.parse_module(module_url, module)
            repos.update(mod_repos)
            packages.update(mod_packages)

        repos = list(repos)
        packages = list(packages)
        log.debug("packages =  %s", packages)

        from time import strftime
        iso_dest = STATIC_FILES+strftime("live-%Y%m%d%H%M.iso")
        with compose_lock:
            global compose_thread
            compose_thread = start_compose_thread(config, iso_dest, url, repos, packages, cancel_q)
            if not compose_thread:
                abort(500, "Starting compose failed.")
            else:
                return {}

    @route('/api/v0/compose/status')
    def compose_status():
        """ Return the current status of the compose
        """
        with compose_lock:
            if not compose_thread:
                return {"status": "compose not started"}
            elif compose_thread.is_alive():
                return {"status": "compose running"}
            else:
                return {"status": "compose finished"}

    @route("/api/v0/compose/types")
    def compose_types():
        """ Return the supported compose types
        """
        return COMPOSE_TYPES

    @route('/api/v0/compose/log/<kbytes:int>')
    def compose_log(kbytes=5):
        """ Read the end of the log, starting back <kbytes> from the end.

        It finds the start of the next line, then returns lines up to the
        current end of the logfile. Last line may not be complete.
        """
        if os.path.exists(config.anaconda_log):
            logfile = config.anaconda_log
        elif os.path.exists(config.logfile):
            logfile = config.logfile
        else:
            return {"lines": []}

        with open(logfile, "r") as f:
            f.seek(0, 2)
            end = f.tell()
            if end < 1024 * kbytes:
                seek_to = 0
            else:
                seek_to = end - (1024 * kbytes)
            f.seek(seek_to, 0)
            f.readline()
            return {"lines": f.readlines()}

    @post('/api/v0/compose/cancel')
    def compose_kill():
        """ Cancel the running compose, if there is one.
        """
        cancel_q.send_cancel()
        return {}

    @route('/api/v0/dnf/transaction/<packages>')
    def dnf_transaction(packages=""):
        """ Return a JSON string with package tuples.

        packages can be a single package or a comma-separated list.
        """
        reply_q = new_reply_q()
        dnf_q.send_transaction(packages.split(","), reply_q)

        (_, args) = reply_q.q.get(True)
        if len(args) < 1:
            abort(500, "Transaction for %s failed." % packages)
        else:
            return args[0]

    @route('/api/v0/dnf/info/<packages>')
    def dnf_info(packages=""):
        """ Return a JSON string with package details.

        packages can be a single packages or a comma-separated list.
        """
        reply_q = new_reply_q()
        dnf_q.send_info(packages.split(","), reply_q)

        (_, args) = reply_q.q.get(True)
        if len(args) < 1:
            abort(500, "Info request for %s failed." % packages)
        else:
            return args[0]

    @route('/api/v0/module/info/<modules>')
    def module_info(modules=""):
        """ Return a JSON string with details about the selected module(s).

        modules can be a single module or a comma-separated list.
        """
        reply = {}
        for module in modules.split(","):
            repos, packages = pylorax.modules.parse_module(MODULE_REPOS, module)
            reply[module] = {"repos": repos, "packages": list(packages)}

        return reply

    @route('/api/v0/module/list')
    def module_list():
        """ Return a JSON string with the list of available modules.

            This is parse_json, accessible through the API, and converted to
            a format that bottle can deal with.
        """
        module_list = pylorax.modules.parse_json(MODULE_REPOS)
        return {"modules" : module_list}

    run(host='0.0.0.0', port=config.port, debug=config.debug)


def main():
    parser = lmc_composer_parser()
    opts = parser.parse_args()
    setup_logging(opts.logfile, log)

    if os.getuid() != 0:
        log.error("You need to run this as root")
        sys.exit(1)

    if not os.path.exists(opts.ks_template):
        log.error("Missing kickstart template: %s", opts.ks_template)
        sys.exit(1)

    # Find the lorax templates
    if opts.lorax_templates and os.path.exists(opts.lorax_templates):
        share_dir = opts.lorax_templates
    elif os.path.exists(os.getcwd()+"/share"):
        share_dir = os.getcwd()+"/share"
    else:
        share_dir = "/usr/share/lorax"
    lorax_templates = find_templates(share_dir)
    log.info("lorax_templates = %s", lorax_templates)

    tempfile.tempdir = opts.tmp
    dnf_dir = opts.dnf_dir or tempfile.mkdtemp(prefix="lmc-dnf.")
    if not os.path.exists(dnf_dir):
        os.makedirs(dnf_dir)
    log.info("Using %s for DNF cache, etc.", dnf_dir)

    # XXX need to clean this up later
    anaconda_log = tempfile.mktemp(prefix="lmc-anaconda.", suffix=".log")
    log.info("Using %s to store logs from anaconda", anaconda_log)

    # Setup a config object to pass around
    _cfg = namedtuple("config", ["project", "releasever", "share_dir", "lorax_templates",
                      "domacboot", "dracut_args", "proxy", "logfile", "port", "debug",
                      "ks_template", "dnf_dir", "anaconda_log"])
    config = _cfg("Fedora", "26", share_dir, lorax_templates, True, DRACUT_DEFAULT,
                  opts.proxy, opts.logfile, opts.port, opts.debug, opts.ks_template, dnf_dir,
                  anaconda_log)

    run_bottle_app(config)


if __name__ == '__main__':
    main()
